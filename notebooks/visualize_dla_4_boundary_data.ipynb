{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "from os.path import exists,join, split, dirname\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from PIL import Image\n",
    "import torch \n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from segment import SegList\n",
    "\n",
    "import dla_up \n",
    "import data_transforms2 as transforms\n",
    "import dataset\n",
    "import pdb\n",
    "\n",
    "try:\n",
    "    from modules import batchnormsync\n",
    "    HAS_BN_SYNC = True \n",
    "except ImportError:\n",
    "    HAS_BN_SYNC = True \n",
    "    \n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch model \n",
    "# model = torch.load('../model_best.pth.tar')\n",
    "model = torch.load('../normal_w_lines_rgb/checkpoint_600.pth.tar')\n",
    "# model = torch.load('/media/sastrygrp2/Backup/dla/boundary_data/unhidden/w_layout/model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'val'\n",
    "data_dir = '/media/sastrygrp2/Backup/boundary_data/unhidden/'\n",
    "# data_dir = 'C:/Users/biosim/oladapo/data/Cityscape/'\n",
    "t = []\n",
    "\n",
    "info = dataset.load_dataset_info(data_dir)\n",
    "normalize = transforms.Normalize(mean=info.mean, std=info.std)\n",
    "# scales = [0.5, 0.75, 1.25, 1.5, 1.75]\n",
    "scales = [0.5, 0.75, 1.25, 1.5]\n",
    "t = []\n",
    "crop_size = 416\n",
    "# if args.crop_size > 0:\n",
    "t.append(transforms.RandomCrop(crop_size))\n",
    "# t.append(transforms.PadToSize(crop_size))\n",
    "t.extend([transforms.ToTensor(), normalize])\n",
    "\n",
    "data = SegList(data_dir, phase, transforms.Compose(t),\n",
    "                       out_name=True, out_size=True,\n",
    "                       binary= True, with_guess=True, with_depth=False, with_normals=True)\n",
    "test_loader = torch.utils.data.DataLoader(data,\n",
    "batch_size=1, shuffle=False, num_workers=1,\n",
    "pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 0\n",
    "# for iter, (im, label, name, size) in enumerate(test_loader):\n",
    "#     j = j+1\n",
    "    \n",
    "    \n",
    "# #     tmp = np.reshape(tmp,(crop_size,crop_size, 3))\n",
    "# #     plt.imshow(np.squeeze(im[0,:,:,:]))\n",
    "#     plt.imshow(tmp)\n",
    "#     plt.show()\n",
    "    \n",
    "#     if j > 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "# print(model.keys())\n",
    "single_model = dla_up.__dict__.get(model['arch'])(\n",
    "        2, down_ratio=2, n_input_channels=7)\n",
    "# single_model.__dict__ = model\n",
    "# print(single_model)\n",
    "# print(model[model.keys()[0]])\n",
    "\n",
    "\n",
    "new_model = torch.nn.DataParallel(single_model).cuda()\n",
    "# print(new_model)\n",
    "\n",
    "# checkpoint = torch.load('../')\n",
    "\n",
    "# start_epoch = checkpoint['epoch']\n",
    "\n",
    "# best_prec1 = checkpoint['best_prec1']\n",
    "\n",
    "\n",
    "new_model.load_state_dict(model['state_dict'])\n",
    "\n",
    "\n",
    "# new_model = torch.nn.DataParallel(single_model).cuda()\n",
    "new_model.eval()\n",
    "# new_model.__dict__ = model\n",
    "# print(new_model.module)\n",
    "# # new_model.load_state_dict(model['state_dict'])\n",
    "k = 0\n",
    "boundaries_prefix = '/media/sastrygrp2/Backup/boundary_data/unhidden/'\n",
    "for  iter, (im, label, name, size) in enumerate(test_loader):\n",
    "    image_var = Variable(im, requires_grad=False, volatile=True)\n",
    "    image_var = image_var.cuda()\n",
    "    print(name)\n",
    "    name_idx = name[k]\n",
    "    gt_filename = boundaries_prefix +'Layout/'+ str(name_idx)[4:]\n",
    "    gt_image = plt.imread(gt_filename)\n",
    "    print(gt_filename)\n",
    "    final = new_model.module(image_var)[0]\n",
    "#     final = single_model(image_var)[0]\n",
    "    _, pred = torch.max(final, 1)\n",
    "    pred = pred.cpu().data.numpy()\n",
    "#     print(pred.shape)\n",
    "#     print(np.amax(pred[k,:,:]))\n",
    "#     print(np.amin(pred[k,:,:]))\n",
    "#     print(pred[k,:,:])\n",
    "    pred_im = []\n",
    "    pred_im = Image.fromarray(pred[k].astype(np.uint8))\n",
    "    input_im =np.squeeze(im.numpy()[k])\n",
    "    print(input_im.shape)\n",
    "    tmp = np.rollaxis(input_im, 0, 3)\n",
    "    print(tmp.shape)\n",
    "    plt.imshow(cv2.cvtColor(np.squeeze(tmp[:,:,0:3]), cv2.COLOR_RGB2BGR))\n",
    "    plt.show()\n",
    "    plt.imshow(tmp[:,:,6])\n",
    "    plt.show()\n",
    "    print(np.amax(np.asarray(pred_im)))\n",
    "    plt.imshow(np.asarray(pred_im))\n",
    "    plt.show()\n",
    "    #plt.imshow(gt_image*255)\n",
    "    #plt.show()\n",
    "    tmp2 = np.squeeze(np.asarray(label))\n",
    "    tmp2[np.where(tmp2 >=255)] = 0\n",
    "    \n",
    "    plt.imshow(tmp2*255)\n",
    "    plt.show()\n",
    "#     plt.hist(np.squeeze(np.asarray(label)).flatten())\n",
    "#     plt.show()\n",
    "    user_in = input(\"Press Enter to continue...\")\n",
    "    \n",
    "    if user_in == 's':\n",
    "        \n",
    "        # create new folder in results directory\n",
    "        dirName = \"./results/\" + str(name_idx)[4:]\n",
    "        print(dirName)\n",
    "        if not os.path.exists(dirName):\n",
    "            os.makedirs(dirName)\n",
    "            print(\"Directory \" , dirName ,  \" Created \")\n",
    "        else:    \n",
    "            print(\"Directory \" , dirName ,  \" already exists\")\n",
    "        \n",
    "        # get images to be saved, save images to directory \n",
    "        RGB_filename = boundaries_prefix +'RGB/'+ str(name_idx)[4:]\n",
    "        RGB_save_filename = dirName + \"/rgb.png\"\n",
    "        input_layer_filename = dirName + \"/input_layer.png\"\n",
    "        guess_filename = dirName + \"/guess.png\"\n",
    "        output_filename =  dirName + \"/output.png\"\n",
    "        ground_truth_filename =  dirName + \"/gt.png\"\n",
    "        \n",
    "        real_RGB = cv2.imread(RGB_filename)\n",
    "        cv2.imwrite(RGB_save_filename, real_RGB)\n",
    "        cv2.imwrite(input_layer_filename, np.squeeze(tmp[:,:,0:3])*255)\n",
    "        cv2.imwrite(guess_filename, np.squeeze(tmp[:,:,3])*255)\n",
    "        cv2.imwrite(output_filename, np.asarray(pred_im)*255)\n",
    "        print(np.asarray(label).shape)\n",
    "        cv2.imwrite(ground_truth_filename, np.squeeze(np.asarray(label))*255)\n",
    "        \n",
    "    elif user_in == 'q':\n",
    "        \n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
